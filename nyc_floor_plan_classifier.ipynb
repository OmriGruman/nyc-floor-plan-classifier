{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nyc_floor_plan_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "bHnUnhcDn5sJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.applications.vgg16 import preprocess_input, VGG16 \n",
        "from keras.optimizers import adam_v2\n",
        "from keras.metrics import categorical_crossentropy"
      ],
      "metadata": {
        "id": "u0Q4yBIWoVF5"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading images\n"
      ],
      "metadata": {
        "id": "j0qGGFEHo2uE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we store the path to our training images and the classes inside a list"
      ],
      "metadata": {
        "id": "ju3QkNNjpIiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"data/train\"\n",
        "test_path = \"data/test\"\n",
        "classes = [\"1\", \"2\", \"3\", \"4\"]"
      ],
      "metadata": {
        "id": "hcraUy5Jpfsb"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we will use our images to generate some augmented images to increase our dataset"
      ],
      "metadata": {
        "id": "ulrUqqU_eZz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_generator = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "                                     rotation_range=5,\n",
        "                                     height_shift_range=0.1,\n",
        "                                     width_shift_range=0.1,\n",
        "                                     shear_range=0.15,\n",
        "                                     horizontal_flip=True,\n",
        "                                     vertical_flip=True)\n",
        "\n",
        "train_images = image_generator.flow_from_directory(train_path,\n",
        "                                                   target_size=(224, 224), \n",
        "                                                   classes=classes, \n",
        "                                                   batch_size=10)\n",
        "\n",
        "images = np.ndarray(shape=(0,224,224,3))\n",
        "labels = np.ndarray(shape=(0,4))\n",
        "for i in range(4 * int(train_images.n / train_images.batch_size)):\n",
        "    imgs, lbls = next(train_images)\n",
        "    images = np.concatenate((images, imgs))\n",
        "    labels = np.concatenate((labels, lbls))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b63d122-d103-4f9e-ec59-c029a405dbc9",
        "id": "Wa8XgicnyUSC"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 240 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building our model\n"
      ],
      "metadata": {
        "id": "b7F17ucx2KO3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we will initialize a pre-trained model, so we will not have to train a full model ourselves"
      ],
      "metadata": {
        "id": "GNvukqof2QK8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_model = VGG16()"
      ],
      "metadata": {
        "id": "6TS9dAXP2YRC"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we will copy its layers but the last one, which we will subtitute with our own output layer of 4 units, according to our number of classes"
      ],
      "metadata": {
        "id": "m2E4vVL42dZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "for layer in vgg16_model.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "    model.add(layer)\n",
        "model.add(Dense(4, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer=adam_v2.Adam(learning_rate=1e-3),\n",
        "              loss=categorical_crossentropy,\n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "xYMTq-li2bID"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, its time to train our model!"
      ],
      "metadata": {
        "id": "wbi9G2ES6u5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(images, labels, \n",
        "                    validation_split=0.2,\n",
        "                    epochs=10, \n",
        "                    verbose=2, \n",
        "                    batch_size=train_images.batch_size)   "
      ],
      "metadata": {
        "id": "yBcsYTrF3BLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how our model did"
      ],
      "metadata": {
        "id": "TUiwXMNr6y5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X-Zj-GtI41pW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uxgYJSFQ5Jcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving our model"
      ],
      "metadata": {
        "id": "xDVupZW27BJt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's save our model in the path below"
      ],
      "metadata": {
        "id": "nnZZ-HbFY0r2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"/content/drive/MyDrive/Models/nyc_floor_plan_classiffier.pkl\""
      ],
      "metadata": {
        "id": "dA3kgres6bno"
      },
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(model_path, \"wb\") as model_file:\n",
        "    pickle.dump(model, model_file)"
      ],
      "metadata": {
        "id": "bOgWOlFMo-Oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reloading the model"
      ],
      "metadata": {
        "id": "6xaPSSJAKDrX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's reload the model we saved in the previous section"
      ],
      "metadata": {
        "id": "98spVXarL88v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(model_path, \"rb\") as model_file:\n",
        "    model_reloaded = pickle.load(model_file)"
      ],
      "metadata": {
        "id": "6TLQh1qmKJnz"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will make sure that the model was loaded correctly"
      ],
      "metadata": {
        "id": "pgDb4pM5MBt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert all([np.array_equal(mrw, mw) for mrw, mw in zip(model_reloaded.get_weights(), model.get_weights())])"
      ],
      "metadata": {
        "id": "F6RkN2aXKdV3"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting an image class"
      ],
      "metadata": {
        "id": "1_sBJj6j40qN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will create a predict function that returns the appropriate class, given an image of a floor plan"
      ],
      "metadata": {
        "id": "UNVNmqfOMgeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image_path):\n",
        "    with open(model_path, \"rb\") as model_file:\n",
        "        model_reloaded = pickle.load(model_file)\n",
        "\n",
        "    image = load_img(image_path, target_size=(224,224))\n",
        "    image = img_to_array(image)\n",
        "    image = image.reshape((1,) + image.shape)\n",
        "\n",
        "    return np.argmax(model_reloaded.predict(image)) + 1"
      ],
      "metadata": {
        "id": "O2hdUH41KlDe"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's load some test images"
      ],
      "metadata": {
        "id": "_gHaIWlHQ-vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = ImageDataGenerator(preprocessing_function=preprocess_input).flow_from_directory(test_path,\n",
        "                                                       target_size=(224, 224), \n",
        "                                                       classes=classes, \n",
        "                                                       batch_size=10)\n",
        "\n",
        "images = np.ndarray(shape=(0,224,224,3))\n",
        "labels = np.ndarray(shape=(0,4))\n",
        "for i in range(int(test_images.n / test_images.batch_size)):\n",
        "    imgs, lbls = next(test_images)\n",
        "    images = np.concatenate((images, imgs))\n",
        "    labels = np.concatenate((labels, lbls))"
      ],
      "metadata": {
        "id": "PVHQz_6-vbgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we will evaluate our predictions"
      ],
      "metadata": {
        "id": "_3gK5yHxRCdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(images)\n",
        "predictions = np.argmax(predictions, axis=-1)\n",
        "labels = np.argmax(labels, axis=-1)\n",
        "\n",
        "cm = confusion_matrix(y_true=labels, \n",
        "                      y_pred=predictions)\n",
        "\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "fJfoH7itQ15K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Prediction rate: {(labels == predictions).mean() * 100}%\")"
      ],
      "metadata": {
        "id": "euc04Q1FVKyS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}